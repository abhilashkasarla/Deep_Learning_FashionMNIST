{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2.1592e+37  3.0746e-41  2.5431e+36\n",
      " 4.5895e-41  4.4497e+31  4.5895e-41\n",
      "-1.0877e+37  3.0746e-41 -1.0877e+37\n",
      " 3.0746e-41 -1.0877e+37  3.0746e-41\n",
      "-1.0877e+37  3.0746e-41  2.5974e+36\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is initialized to some garbage values to a 5x3 matrix. type of x is float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5726  0.4047  0.8376\n",
      " 0.7681  0.9332  0.4658\n",
      " 0.8262  0.3670  0.8438\n",
      " 0.1617  0.6400  0.0325\n",
      " 0.3027  0.7480  0.1013\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.5241  0.9108 -0.3673\n",
      "-0.1180 -1.8444 -0.9367\n",
      " 1.1123 -0.2618  0.0601\n",
      " 1.7041  0.1941  1.4117\n",
      " 1.0187  0.9183  0.6491\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "y2 = torch.randn(5, 3)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is intialized randomly by picking samples from uniform distribution [0,1]. type of y is float.\n",
    "if randn is used samples are picked from normal distribution instead of uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2.1592e+37  3.0746e-41  2.5431e+36\n",
      " 4.5895e-41  4.4497e+31  4.5895e-41\n",
      "-1.0877e+37  3.0746e-41 -1.0877e+37\n",
      " 3.0746e-41 -1.0877e+37  3.0746e-41\n",
      "-1.0877e+37  3.0746e-41  2.5974e+36\n",
      "[torch.DoubleTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.5726  0.4047  0.8376\n",
      " 0.7681  0.9332  0.4658\n",
      " 0.8262  0.3670  0.8438\n",
      " 0.1617  0.6400  0.0325\n",
      " 0.3027  0.7480  0.1013\n",
      "[torch.DoubleTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=x.double()\n",
    "y=y.double()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type of x and y is now Double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  torch.Size([5, 3]) , y.shape:  torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch . Tensor ([[ -0.1859 , 1.3970 , 0.5236] ,\n",
    "[ 2.3854 , 0.0707 , 2.1970] ,\n",
    "[ -0.3587 , 1.2359 , 1.8951] ,\n",
    "[ -0.1189 , -0.1376 , 0.4647] ,\n",
    "[ -1.8968 , 2.0164 , 0.1092]])\n",
    "y = torch . Tensor ([[ 0.4838 , 0.5822 , 0.2755] ,\n",
    "[ 1.0982 , 0.4932 , -0.6680] ,\n",
    "[ 0.7915 , 0.6580 , -0.5819] ,\n",
    "[ 0.3825 , -1.1822 , 1.5217] ,\n",
    "[ 0.6042 , -0.2280 , 1.3210]])\n",
    "print('x.shape: ',x.shape,', y.shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack:  torch.Size([2, 5, 3])\n",
      "concatenate along axis 0:  torch.Size([10, 3])\n",
      "concatenate along axis 1:  torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "z=torch.stack((x,y))\n",
    "print('stack: ',z.shape)\n",
    "z1=torch.cat((x,y), 0)     # concatenate along axis=0\n",
    "print('concatenate along axis 0: ',z1.shape)\n",
    "z2=torch.cat((x,y), 1)     # concatenate along axis=1\n",
    "print('concatenate along axis 1: ', z2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape of z is (2,5,3). if torch.cat((x, y), 0) was used it concatenates along axis=0, the shape would be (10,3). and if torch.cat((x, y), 1) the shape would be (5,6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32099997997\n",
      "1.32099997997\n"
     ]
    }
   ],
   "source": [
    "print(y[4,2])\n",
    "print(z[1,4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.1092\n",
      " 1.3210\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(z[:,4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2979  1.9792  0.7991\n",
      " 3.4836  0.5639  1.5290\n",
      " 0.4328  1.8939  1.3132\n",
      " 0.2636 -1.3198  1.9864\n",
      "-1.2926  1.7884  1.4302\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.2979  1.9792  0.7991\n",
      " 3.4836  0.5639  1.5290\n",
      " 0.4328  1.8939  1.3132\n",
      " 0.2636 -1.3198  1.9864\n",
      "-1.2926  1.7884  1.4302\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.2979  1.9792  0.7991\n",
      " 3.4836  0.5639  1.5290\n",
      " 0.4328  1.8939  1.3132\n",
      " 0.2636 -1.3198  1.9864\n",
      "-1.2926  1.7884  1.4302\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.2979  1.9792  0.7991\n",
      " 3.4836  0.5639  1.5290\n",
      " 0.4328  1.8939  1.3132\n",
      " 0.2636 -1.3198  1.9864\n",
      "-1.2926  1.7884  1.4302\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (x + y)\n",
    "print ( torch .add(x, y))\n",
    "print (x.add(y))\n",
    "torch .add(x, y, out=x)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are printing the same output. All are equivalent, but using torch.add(), we can do inplace addition to tensor x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "y=x.view(16)\n",
    "z=x.view(-1,8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is the reshaped version of x in 1D i.e of length 16. z's shape is (2,8). By passing -1 in one dimension, the exact size in that dimension is calculated based on other dimensions. Like here e.g. the total elements were 16, and we passed (-1,8), so ihas to be 2 in the -1 dimension to accomodate 16 elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(10,10)\n",
    "y=torch.randn(2,100)\n",
    "z=torch.mm(x.view(1,100),y.view(100,2))\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[1. 1. 1. 1. 1.]\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a is Tensor float, b is a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a[0] += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes they match implying they share underlying memory locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 5]\n",
      " [3. 2. 2. 2. 2.]\n",
      "\n",
      " 4\n",
      " 3\n",
      " 3\n",
      " 3\n",
      " 3\n",
      "[torch.FloatTensor of size 5]\n",
      " [4. 3. 3. 3. 3.]\n",
      "\n",
      " 5\n",
      " 4\n",
      " 4\n",
      " 4\n",
      " 4\n",
      "[torch.FloatTensor of size 5]\n",
      " [4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a, b)\n",
    "# a = torch.ones(5)\n",
    "a[:] += 1\n",
    "print(a, b)\n",
    "# a = torch.ones(5)\n",
    "a = a.add(1)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All operations have the effect of adding 1 to all elements in the tensor. But for numpy array only a.add(1) doesn't add 1 to the numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out =a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2.1337 -1.2728 -0.3782\n",
      " 0.2924 -2.2481 -1.7495\n",
      " 2.1714  0.9560 -0.9908\n",
      " 0.4519  1.6993  1.8722\n",
      "-0.8221  0.5725  1.4134\n",
      "[torch.cuda.FloatTensor of size 5x3 (GPU 0)]\n",
      "\n",
      "\n",
      "-2.1337 -1.2728 -0.3782\n",
      " 0.2924 -2.2481 -1.7495\n",
      " 2.1714  0.9560 -0.9908\n",
      " 0.4519  1.6993  1.8722\n",
      "-0.8221  0.5725  1.4134\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 3)\n",
    "y = torch.randn(5, 3)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "z = x+y\n",
    "print(z)\n",
    "if torch.cuda.is_available():\n",
    "    print(z.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU is available the tensor object is cuda.FloatTensor. The result would have been same even if it was run on a CPU only architecture, only the runtimes would have been different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.1337316  -1.2728078  -0.3781566 ]\n",
      " [ 0.29239255 -2.2481313  -1.7495407 ]\n",
      " [ 2.17141     0.95599705 -0.99079937]\n",
      " [ 0.45188344  1.6993074   1.8722131 ]\n",
      " [-0.8221155   0.5724528   1.413386  ]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "can't convert CUDA tensor to numpy (it doesn't support GPU arrays). Use .cpu() to move the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-11d5c486e6eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). Use .cpu() to move the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Z from GPU to numpy is throwing an error saying it does not support GPU arrays. We need to move to host memory first using the .cpu() and then convert to numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd as ag\n",
    "\n",
    "x = ag.Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(x)\n",
    "y = x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is also a float tensor variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "f = z.mean()\n",
    "print(z, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "f = \\frac{3*[(x_1+2)^2 + (x_2+2)^2 + (x_3+2)^2 + (x_4+2)^2]}{4}\n",
    "\\end{align}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of f is [[4.5, 4.5], [4.5, 4.5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "(\\nabla_xf)_i = \\frac{3*(x_i+2)}{2}\n",
    "\\end{align}\n",
    "\n",
    "with xi=1, we have the correct answer as 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNISTtools\n",
    "import matplotlib.pyplot as plt\n",
    "xtrain, ltrain = MNISTtools.load(dataset='training', path='/datasets/MNIST')\n",
    "xtest, ltest = MNISTtools.load(dataset='testing', path='/datasets/MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape:  (784, 60000)\n",
      "xtest.shape:  (784, 10000)\n"
     ]
    }
   ],
   "source": [
    "print('xtrain shape: ',xtrain.shape)\n",
    "print('xtest.shape: ',xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_MNIST_images(x):\n",
    "    x=x.astype(np.float64)\n",
    "    return (x*2/255.0)-1.0\n",
    "    \n",
    "xtrain=normalize_MNIST_images(xtrain)\n",
    "xtest=normalize_MNIST_images(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "m,n=xtrain.shape\n",
    "train=xtrain.T.reshape((n, 28, 28))\n",
    "train=train[:,None,:,:]           # to add 1 dimension for channel\n",
    "print(train.shape)\n",
    "train=np.moveaxis(train,2,-1)     # as it wants width x height\n",
    "# plt.imshow(train[42,0,:,:], cmap='gray')\n",
    "# print(ltrain[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "m,n=xtest.shape\n",
    "test=xtest.T.reshape((n, 28, 28))\n",
    "test=test[:,None,:,:]           # to add 1 dimension for channel\n",
    "print(test.shape)\n",
    "test=np.moveaxis(test,2,-1)     # as it wants width x height\n",
    "# plt.imshow(train[42,0,:,:], cmap='gray')\n",
    "# print(ltrain[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is:  7\n"
     ]
    }
   ],
   "source": [
    "MNISTtools.show(train [42 , 0, :, :])\n",
    "print('label is: ',ltrain[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = ag.Variable( torch.from_numpy(train), requires_grad=False)\n",
    "ltrain = ag.Variable( torch.from_numpy(ltrain), requires_grad=False)\n",
    "xtest = ag.Variable( torch.from_numpy(test), requires_grad = False)\n",
    "ltest = ag.Variable( torch.from_numpy(ltest), requires_grad = False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    xtrain = xtrain.cuda()\n",
    "    ltrain = ltrain.cuda()\n",
    "    xtest = xtest.cuda()\n",
    "    ltest = ltest.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) output after convolutional layer KxK = 5x5, C=6, ReLu and maxpooling: N x 6 x (28-5+1)/2 x (28-5+1)/2  \n",
    "N x 6 x 12 x 12. Lets ignore N (total images). then it is 6x12x12.\n",
    "\n",
    "(b) output after convolutional layer KxK = 5x5, C=16, ReLu and maxpooling: 16 x (12-5+1)/2 x (12-5+1)/2  \n",
    "16 x 4 x 4      (ignoring N)\n",
    "\n",
    "Third layer has 16x4x4 = 256 input units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet , self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5).double()\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5).double()\n",
    "        self.fc1 = nn.Linear(256 , 120).double()\n",
    "        self.fc2 = nn.Linear(120 , 84).double()\n",
    "        self.fc3 = nn.Linear(84 , 10).double()\n",
    "#         if torch.cuda.is_available():\n",
    "#             self.conv1=self.conv1.cuda()\n",
    "#             self.conv2=self.conv2.cuda()\n",
    "#             self.fc1 = self.fc1.cuda()\n",
    "#             self.fc2 = self.fc2.cuda()\n",
    "#             self.fc3 = self.fc3.cuda()\n",
    "        \n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self , x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "#         if torch.cuda.is_available():\n",
    "#             x = x.cpu()\n",
    "        return x\n",
    "    \n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self , x):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net = LeNet().cuda()\n",
    "else:\n",
    "    net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([6, 1, 5, 5])\n",
      "1 torch.Size([6])\n",
      "2 torch.Size([16, 6, 5, 5])\n",
      "3 torch.Size([16])\n",
      "4 torch.Size([120, 256])\n",
      "5 torch.Size([120])\n",
      "6 torch.Size([84, 120])\n",
      "7 torch.Size([84])\n",
      "8 torch.Size([10, 84])\n",
      "9 torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "for i in range(len(params)):\n",
    "    print(i, params[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These must be the weights and biases. The parameters corresponding to even indices are weights of the convolutional kerels or fully connected layer. parameters of odd indices are corresponding layer's biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(pred, labels):\n",
    "    return (100 * np.mean(labels == pred.data.numpy().T.argmax(axis=0)))\n",
    "\n",
    "def performance_using_gpu(pred, labels):\n",
    "    max_index = pred.max(dim = 1)[1]\n",
    "    acc = (max_index==labels).float().sum()/max_index.size()[0]\n",
    "    return 100*acc.cpu().data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.26\n"
     ]
    }
   ],
   "source": [
    "yinit = net(xtest)\n",
    "if torch.cuda.is_available():\n",
    "    yinit = yinit.cpu()\n",
    "    labels = ltest.cpu().data.numpy()\n",
    "print(performance(yinit, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 12.47% (varies with randomness) with random initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = xtrain.size()[0] # Training set size\n",
    "B = 100 # Minibacth size\n",
    "NB = int(np.ceil(N/B)) # Number of minibatches\n",
    "T = 10 # Number of epochs\n",
    "gamma = .001 # learning rate\n",
    "rho = .9 # momentum\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = gamma , momentum = rho )\n",
    "# PyTorch’s CrossEntropyLoss is the composition of a softmax activation with the standard cross-entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     ltrain=ltrain.cpu()\n",
    "def train_net(net, xtrain, ltrain, validation=False):\n",
    "    print('inside training')\n",
    "    N = xtrain.size()[0] # Training set size\n",
    "    B = 100 # Minibacth size\n",
    "    cv_acc=[]\n",
    "    cv_losses=[]\n",
    "    if validation:\n",
    "        print('inside validation')\n",
    "        idx=np.arange(N)\n",
    "        np.random.shuffle(idx)\n",
    "        cv_xtrain=xtrain[idx[0:int(0.1*N)]]\n",
    "        cv_ltrain=ltrain[idx[0:int(0.1*N)]]\n",
    "        xtrain=xtrain[idx[int(0.1*N):N]]\n",
    "        ltrain=ltrain[idx[int(0.1*N):N]]\n",
    "        print('xtrain: ',len(xtrain))\n",
    "        print('ltrain: ',len(ltrain))\n",
    "        print('xtrain: ',len(cv_xtrain))\n",
    "        print('ltrain: ',len(cv_ltrain))\n",
    "        N=len(xtrain)\n",
    "        \n",
    "    NB = int(np.ceil(N/B)) # Number of minibatches\n",
    "    T = 2 # Number of epochs\n",
    "    gamma = .001 # learning rate\n",
    "    rho = .9 # momentum\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = gamma , momentum = rho )\n",
    "    \n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        idxminibatches = np.random.permutation(NB) # shuffling\n",
    "        for k in range(NB):\n",
    "            i = idxminibatches[k] # index of minibatch\n",
    "            # Extract i-th minibatch from xtrain and ltrain\n",
    "            idxsmp = np.arange(B*i, min(B*(i+1), N)) # indices of samples for i-th minibatch\n",
    "            inputs = xtrain[ idxsmp ]\n",
    "            labels = ltrain[ idxsmp ]\n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs , labels )\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "            # Print averaged loss per minibatch every 100 mini - batches\n",
    "            running_loss += loss [0]\n",
    "            if k % 500 == 499:\n",
    "                print ('[%d, %5d]  loss : %.3f'%( epoch + 1, k + 1, running_loss/500 ))\n",
    "                running_loss = 0.0\n",
    "        if validation:\n",
    "            predsCuda = net(cv_xtrain)\n",
    "            cv_loss = criterion(predsCuda , cv_ltrain )[0]\n",
    "            acc=performance_using_gpu(predsCuda, cv_ltrain)\n",
    "            cv_acc.append(acc)\n",
    "            cv_losses.append(cv_loss)\n",
    "    return net, cv_acc, cv_losses\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside training\n",
      "inside validation\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1523240155148/work/torch/lib/THC/generic/THCTensorIndex.cu:767",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-346359577d6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mltrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(cv_acc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-24143e0171f4>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, xtrain, ltrain, validation)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcv_xtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcv_ltrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mltrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mxtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mIndexSelect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# else fall through and raise an error in Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, index)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# handle any Variable arguments in the index sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preprocess_adv_index_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1523240155148/work/torch/lib/THC/generic/THCTensorIndex.cu:767"
     ]
    }
   ],
   "source": [
    "net, cv_acc, cv_losses = train_net(net, xtrain, ltrain, validation=True)\n",
    "print('Finished Training')\n",
    "# print(cv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2-D, but have shapes (10,) and (10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-52f4b1ff2475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n\u001b[0;32m--> 245\u001b[0;31m                              \"shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (10,) and (10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(cv_acc)\n",
    "plt.show()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(cv_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(xtest)\n",
    "if torch.cuda.is_available():\n",
    "    pred = pred.cpu()\n",
    "    labels = ltest.cpu().data.numpy()\n",
    "print(performance(pred, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy after training using GPUs is 98.12% (varies with randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsCuda = net(xtest)\n",
    "if torch.cuda.is_available():\n",
    "    pred = predsCuda.cpu()\n",
    "    labels = ltest.cpu().data.numpy()\n",
    "print(performance(pred, labels))\n",
    "print(performance_using_gpu(predsCuda, ltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "cv_xtrain=xtrain[idx[0:int(0.1*N)]]\n",
    "cv_ltrain=ltrain[idx[0:int(0.1*N)]]\n",
    "dxtrain=xtrain[idx[int(0.1*N):N]]\n",
    "dltrain=ltrain[idx[int(0.1*N):N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dltrain))\n",
    "print(len(cv_ltrain))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
