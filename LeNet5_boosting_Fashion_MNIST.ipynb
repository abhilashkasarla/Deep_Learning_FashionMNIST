{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as ag\n",
    "import mnist_reader\n",
    "import MNISTtools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ltrain = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
    "xtest, ltest = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
    "xtrain, xtest = xtrain.T, xtest.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('xtrain shape: ',xtrain.shape)\n",
    "print('xtest.shape: ',xtest.shape)\n",
    "print('ltrain.shape: ',ltrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_MNIST_images(x):\n",
    "    x=x.astype(np.float64)\n",
    "    return (x*2/255.0)-1.0\n",
    "    \n",
    "xtrain=normalize_MNIST_images(xtrain)\n",
    "xtest=normalize_MNIST_images(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n=xtrain.shape\n",
    "train=xtrain.T.reshape((n, 28, 28))\n",
    "train=train[:,None,:,:]           # to add 1 dimension for channel\n",
    "print(train.shape)\n",
    "# train=np.moveaxis(train,2,-1)     # as it wants width x height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n=xtest.shape\n",
    "test=xtest.T.reshape((n, 28, 28))\n",
    "test=test[:,None,:,:]           # to add 1 dimension for channel\n",
    "print(test.shape)\n",
    "# test=np.moveaxis(test,2,-1)     # as it wants width x height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNISTtools.show(train [42 , 0, :, :])\n",
    "print('label is: ',ltrain[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = ag.Variable( torch.from_numpy(train), requires_grad=False)\n",
    "ltrain = ag.Variable( torch.from_numpy(ltrain).long(), requires_grad=False)\n",
    "xtest = ag.Variable( torch.from_numpy(test), requires_grad = False)\n",
    "ltest = ag.Variable( torch.from_numpy(ltest).long(), requires_grad = False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    xtrain = xtrain.cuda()\n",
    "    ltrain = ltrain.cuda()\n",
    "    xtest = xtest.cuda()\n",
    "    ltest = ltest.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) output after convolutional layer KxK = 5x5, C=6, ReLu and maxpooling: N x 6 x (28-5+1)/2 x (28-5+1)/2  \n",
    "N x 6 x 12 x 12. Lets ignore N (total images). then it is 6x12x12.\n",
    "\n",
    "(b) output after convolutional layer KxK = 5x5, C=16, ReLu and maxpooling: 16 x (12-5+1)/2 x (12-5+1)/2  \n",
    "16 x 4 x 4      (ignoring N)\n",
    "\n",
    "Third layer has 16x4x4 = 256 input units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet , self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5).double()\n",
    "        self.conv1_drop = nn.Dropout2d()\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5).double()\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(256 , 120).double()\n",
    "        self.fc2 = nn.Linear(120 , 84).double()\n",
    "        self.fc3 = nn.Linear(84 , 10).double()\n",
    "        \n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self , x):\n",
    "        # x = F.max_pool2d(F.relu(self.conv1_drop(self.conv1(x))),(2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2_drop(self.conv2(x))),(2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)   # for dropout\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)   # for dropout\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self , x):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     net = LeNet().cuda()\n",
    "# else:\n",
    "#     net = LeNet()\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(pred, labels):\n",
    "    return (100 * np.mean(labels == pred.data.numpy().T.argmax(axis=0)))\n",
    "\n",
    "def performance_using_gpu(pred, labels):\n",
    "    max_index = pred.max(dim = 1)[1]\n",
    "    acc = (max_index==labels).float().sum()/max_index.size()[0]\n",
    "    return 100*acc.cpu().data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yinit = net(xtest)\n",
    "# # if torch.cuda.is_available():\n",
    "# #     yinit = yinit.cpu()\n",
    "# #     labels = ltest.cpu().data.numpy()\n",
    "# print(performance_using_gpu(yinit, ltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = xtrain.size()[0] # Training set size\n",
    "B = 100 # Minibacth size\n",
    "NB = int(np.ceil(N/B)) # Number of minibatches\n",
    "T = 10 # Number of epochs\n",
    "gamma = .001 # learning rate\n",
    "rho = .9 # momentum\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = gamma , momentum = rho )\n",
    "# PyTorchâ€™s CrossEntropyLoss is the composition of a softmax activation with the standard cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     ltrain=ltrain.cpu()\n",
    "def train_net(net, xtrain, ltrain, T=10, validation=False):\n",
    "    net.train()    # to set training boolean to true, used in dropout\n",
    "    start=time.time()\n",
    "    N = xtrain.size()[0] # Training set size\n",
    "    #B = 100 # Minibacth size\n",
    "    cv_acc, test_acc = [],[]\n",
    "    cv_losses, test_losses = [],[]\n",
    "    train_losses=[]\n",
    "    if validation:\n",
    "        idx=np.arange(N)\n",
    "        np.random.shuffle(idx)\n",
    "        cv_xtrain=xtrain[idx[0:int(0.1*N)]]\n",
    "        cv_ltrain=ltrain[idx[0:int(0.1*N)]]\n",
    "        xtrain=xtrain[idx[int(0.1*N):N]]\n",
    "        ltrain=ltrain[idx[int(0.1*N):N]]\n",
    "        # print('xtrain: ',len(xtrain))\n",
    "        # print('ltrain: ',len(cv_ltrain))\n",
    "        N=len(xtrain)\n",
    "        \n",
    "    NB = int(np.ceil(N/B)) # Number of minibatches\n",
    "    # T = 20 # Number of epochs\n",
    "    #gamma = .001 # learning rate\n",
    "    #rho = .9 # momentum\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(net.parameters(), lr = gamma , momentum = rho )\n",
    "    metrics={}\n",
    "    train_loss=0.0\n",
    "    for epoch in tqdm_notebook(range(T)):\n",
    "        running_loss = 0.0\n",
    "        idxminibatches = np.random.permutation(NB) # shuffling\n",
    "        running_loss = 0.0\n",
    "        for k in range(NB):\n",
    "            i = idxminibatches[k] # index of minibatch\n",
    "            # Extract i-th minibatch from xtrain and ltrain\n",
    "            idxsmp = np.arange(B*i, min(B*(i+1), N)) # indices of samples for i-th minibatch\n",
    "            inputs,labels = xtrain[idxsmp], ltrain[idxsmp]\n",
    "            \n",
    "            optimizer.zero_grad()                 # Initialize the gradients to zero\n",
    "            outputs = net(inputs)                 # Forward propagation\n",
    "            loss = criterion(outputs , labels )   # Error evaluation\n",
    "            loss.backward()                       # Back propagation\n",
    "            optimizer.step()                      # Parameter update\n",
    "            \n",
    "            # Print averaged loss per minibatch every 100 mini - batches\n",
    "            running_loss += loss [0]\n",
    "            #if k % 500 == 499:\n",
    "            #    print ('[%d, %5d]  loss : %.3f'%( epoch + 1, k + 1, running_loss/500 ))\n",
    "            #    running_loss = 0.0\n",
    "        if validation and epoch%5==4 :\n",
    "            predsCuda = net(cv_xtrain)\n",
    "            cv_acc.append( performance_using_gpu(predsCuda, cv_ltrain) )\n",
    "            cv_losses.append(criterion(predsCuda , cv_ltrain )[0].cpu().data.numpy()[0] )\n",
    "            \n",
    "            predsCuda = net(xtest)\n",
    "            acc = performance_using_gpu(predsCuda, ltest)\n",
    "            test_acc.append( acc )\n",
    "            test_losses.append( criterion(predsCuda , ltest )[0].cpu().data.numpy()[0] )\n",
    "            train_losses.append((running_loss/NB).cpu().data.numpy()[0])\n",
    "            # print ('%d  test_acc : %.3f'%( epoch + 1, acc))\n",
    "            \n",
    "    metrics['cv_acc'], metrics['cv_losses'] = cv_acc,cv_losses\n",
    "    metrics['test_acc'], metrics['test_losses'] = test_acc,test_losses\n",
    "    metrics['train_losses'] = train_losses\n",
    "    print('Total time taken in training (secs): ',time.time()-start)\n",
    "    return net, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline (with given hyperparamerters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     net = LeNet().cuda()\n",
    "# else:\n",
    "#     net = LeNet()\n",
    "    \n",
    "# B = 100          # Minibacth size\n",
    "# gamma = .001     # learning rate\n",
    "# rho = .9         # momentum\n",
    "# T=200            # epochs\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr = gamma , momentum = rho )\n",
    "\n",
    "# net, metrics = train_net(net, xtrain, ltrain, T, validation=True)\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    xlimits=range(0,T,5)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    i=1\n",
    "    metrics_keys = ['cv_acc','cv_losses','train_losses','test_acc','test_losses']\n",
    "    titles = ['validation accuracy', 'validation loss', 'training loss',\\\n",
    "             'test accuracy', 'test losses']\n",
    "    for metric,title in zip(metrics_keys, titles):\n",
    "        plt.subplot(2,3,i)\n",
    "        plt.plot(xlimits, metrics[metric])\n",
    "        plt.title(title)\n",
    "        i+=1\n",
    "    plt.subplots_adjust(right=2)\n",
    "    fig=plt.gcf()               # store the plot to store it later\n",
    "    plt.show()\n",
    "    return fig\n",
    "        \n",
    "# fig=plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=str(time.strftime(\"%c\"))\n",
    "# fig.savefig('plots/'+ 'baseline result __ '+ t +'.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment hyperparameters and optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net = LeNet().cuda()\n",
    "else:\n",
    "    net = LeNet()\n",
    "    \n",
    "B = 100          # Minibacth size\n",
    "gamma = .003     # learning rate\n",
    "rho = 0.9         # momentum\n",
    "T=100            # epochs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = gamma , momentum = rho )\n",
    "\n",
    "net, metrics = train_net(net, xtrain, ltrain, T, validation=True)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_metrics(metrics)\n",
    "t=str(time.strftime(\"%c\"))\n",
    "# fig.savefig('plots/'+ ' dropouts after convls, FCs gamma=0.003__ '+ t +'.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "net.eval()      # to set training boolean to false, used for not applying dropout\n",
    "predsCuda = net(xtest)\n",
    "if torch.cuda.is_available():\n",
    "    pred = predsCuda.cpu()\n",
    "    labels = ltest.cpu().data.numpy()\n",
    "print(performance_using_gpu(predsCuda, ltest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
